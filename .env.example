# SynthForge.AI Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# REQUIRED: Azure AI Foundry Project
# =============================================================================
# Format: https://<resource>.services.ai.azure.com/api/projects/<project-id>
PROJECT_ENDPOINT=

# =============================================================================
# REQUIRED: Model Deployments
# =============================================================================
# GPT-4o model for general agent reasoning
MODEL_DEPLOYMENT_NAME=gpt-4o

# GPT-4o Vision model for diagram analysis (VisionAgent + OCRDetectionAgent)
# Both agents use the same vision-capable model - no additional deployment needed
VISION_MODEL_DEPLOYMENT_NAME=gpt-4o

# GPT-4.1 model for Infrastructure as Code generation (Phase 2 - ModuleDevelopmentAgent)
# Optimized for code generation with improved reasoning for Terraform/Bicep modules
# Falls back to MODEL_DEPLOYMENT_NAME if not specified
IAC_MODEL_DEPLOYMENT_NAME=gpt-4.1

# =============================================================================
# REQUIRED FOR OCR/SECURITY AGENTS: Bing Grounding Connection
# =============================================================================
# The OCRDetectionAgent and SecurityAgent use Bing Grounding to look up:
# - Azure CAF naming conventions and abbreviations
# - Security best practices and RBAC roles
# - Private endpoint configurations
#
# Create a Bing connection in Azure AI Foundry:
# 1. Go to Azure AI Foundry portal
# 2. Navigate to your project > Connections
# 3. Add connection > Bing Search
# 4. Copy the connection ID (full resource path)
#
# Format: /subscriptions/<sub>/resourceGroups/<rg>/providers/Microsoft.MachineLearningServices/workspaces/<project>/connections/<connection-name>
BING_CONNECTION_ID=

# =============================================================================
# OPTIONAL: Detection & Clarification Settings
# =============================================================================
# Threshold below which user clarification is requested (default: 0.7)
CONFIDENCE_THRESHOLD=0.7

# Minimum detection confidence to include (default: 0.5)
# CLARIFICATION_THRESHOLD=0.5

# =============================================================================
# OPTIONAL: Model Consistency Settings
# =============================================================================
# Temperature for model responses (0.0-1.0)
# Lower values = more deterministic/consistent results across runs
# Recommended: 0.1 for consistent architecture extraction
# MODEL_TEMPERATURE=0.1

# =============================================================================
# OPTIONAL: Output & Logging
# =============================================================================
OUTPUT_DIR=./output
LOG_LEVEL=INFO

# Enable debug logging
# DEBUG=false

# =============================================================================
# OPTIONAL: OCR Service Selection
# =============================================================================
# The OCR service preference for text extraction. Options:
# - "auto"    : Try Computer Vision first, then Document Intelligence, then GPT-4o (DEFAULT)
# - "vision"  : Use Computer Vision only
# - "document_intelligence" : Use Document Intelligence only  
# - "gpt4o"   : Skip specialized OCR, use GPT-4o vision only
#
# For architecture diagrams, Computer Vision (auto or vision) is recommended.
# OCR_SERVICE=auto

# =============================================================================
# OPTIONAL: Azure Computer Vision (for enhanced OCR)
# =============================================================================
# By default, SynthForge uses your existing Foundry endpoint for Computer Vision.
# Azure AI Foundry projects are backed by Azure AI Services which includes CV.
#
# The endpoint is auto-derived from PROJECT_ENDPOINT and uses DefaultAzureCredential.
# No additional configuration needed in most cases!
#
# Only set these if you want to use a SEPARATE Computer Vision resource:
# AZURE_VISION_ENDPOINT=https://<resource-name>.cognitiveservices.azure.com/
# AZURE_VISION_KEY=<your-key>  # Only needed for legacy SDK

# =============================================================================
# OPTIONAL: Azure Document Intelligence (for documents, not diagrams)
# =============================================================================
# Document Intelligence is better for structured documents (forms, invoices)
# For diagrams, Computer Vision is preferred.

# Document Intelligence endpoint
# Format: https://<resource-name>.cognitiveservices.azure.com/
# DOCUMENT_INTELLIGENCE_ENDPOINT=

# Document Intelligence key
# DOCUMENT_INTELLIGENCE_KEY=

# =============================================================================
# OCR Service Selection
# =============================================================================
# Options:
# - "auto" (default): Try Computer Vision first, then Document Intelligence
# - "vision" or "computer_vision": Use Azure Computer Vision (RECOMMENDED for diagrams)
# - "document_intelligence": Use Azure Document Intelligence (better for documents)
# - "gpt4o": Use GPT-4o built-in OCR (fallback, convenient but less accurate)
OCR_SERVICE=auto

# =============================================================================
# REQUIRED: Microsoft MCP Server
# =============================================================================
# CHOOSE ONE of the following options:
#
# OPTION 1: Microsoft Foundry MCP (RECOMMENDED)
# - Unified MCP server for models, knowledge, evaluation, and more
# - Cloud-hosted: https://mcp.ai.azure.com
# - No installation required
# - Best for: Phase 1 + general AI workflows
# - Documentation: https://learn.microsoft.com/azure/ai-foundry/mcp/get-started
#
# OPTION 2: Microsoft Learn MCP (Dedicated Documentation Search)
# - Specialized for Microsoft Learn documentation search
# - Cloud-hosted: https://learn.microsoft.com/api/mcp
# - Tools: microsoft_docs_search, microsoft_docs_fetch, microsoft_code_sample_search
# - Best for: Dedicated documentation search workflows only
#
# Reference: https://github.com/microsoft/mcp
MS_LEARN_MCP_URL=https://mcp.ai.azure.com

# =============================================================================
# PHASE 2: IaC Generation MCP Servers (OPTIONAL)
# =============================================================================
# For enhanced Bicep/Terraform generation, choose your setup approach:
#
# CURRENT APPROACH: Zero-dependency (Bing Grounding + Foundry MCP + GPT-4o)
# - Works well for most scenarios
# - No additional installations required
# - Agents fallback to web research + code generation
#
# ENHANCED APPROACH: Add specialized MCP servers for advanced workflows
# - Azure MCP: All-in-one Azure tooling (Recommended)
# - Individual MCPs: Fine-grained control per domain (Advanced)
#
# See .env_RECOMMENDED_UPDATES.md for detailed guidance.
# Reference: https://github.com/microsoft/mcp

# =============================================================================
# RECOMMENDED: Azure MCP (All-in-One)
# =============================================================================
# Azure MCP Server - Comprehensive Azure capabilities
# Provides: Azure CLI, Resource Manager, Bicep support, and more
# TYPE: Local (requires installation)
# INSTALL: VS Code extension `ms-azuretools.vscode-azure-mcp-server`
#   OR: npx -y @azure/mcp-server
# BENEFIT: All Azure tools in one server, including Bicep generation
# REPLACES: BICEP_MCP_URL, AZURE_DEVOPS_MCP_URL (basic capabilities)
# AZURE_MCP_URL=http://localhost:3100
AZURE_MCP_URL=

# =============================================================================
# ADVANCED: Individual Specialized MCP Servers
# =============================================================================
# Use these only if you need fine-grained control or specific features
# not available in Azure MCP.

# Bicep MCP Server (HIGH PRIORITY - Required for advanced Bicep generation)
# Provides: Bicep best practices, Azure Verified Modules, resource schemas
# TYPE: Local (requires Node.js/npx)
# INSTALL: npx -y @microsoft/mcp-server-bicep
# GitHub: https://github.com/microsoft/mcp
# NOTE: Azure MCP includes basic Bicep support
# BICEP_MCP_URL=http://localhost:3101
BICEP_MCP_URL=

# Terraform MCP Server - HashiCorp Official (HIGH PRIORITY for Terraform users)
# Provides: Terraform Registry, provider docs, HCP Terraform integration
# TYPE: Local (requires Docker)
# INSTALL: docker run -p 3102:3102 hashicorp/terraform-mcp-server
# GitHub: https://github.com/hashicorp/terraform-mcp-server
# BENEFIT: Official HashiCorp integration, HCP Terraform support
# TERRAFORM_MCP_URL=http://localhost:3102
TERRAFORM_MCP_URL=

# Optional: HCP Terraform token for workspace management
# TFE_TOKEN=

# Azure DevOps MCP Server (MEDIUM PRIORITY - Optional, can fallback to Bing)
# Provides: Azure Pipelines templates, DevOps best practices
# TYPE: Local (requires Node.js/npx)
# INSTALL: npx -y @azure-devops/mcp <org-name>
# GitHub: https://github.com/microsoft/azure-devops-mcp
# NOTE: Azure MCP includes basic DevOps capabilities
# AZURE_DEVOPS_MCP_URL=http://localhost:3103
AZURE_DEVOPS_MCP_URL=

# Optional: Azure DevOps PAT
# AZURE_DEVOPS_PAT=

# GitHub MCP Server (MEDIUM PRIORITY - Cloud-hosted, no installation)
# Provides: GitHub Actions templates, workflow best practices, repo integration
# TYPE: REMOTE - Cloud-hosted at https://api.githubcopilot.com/mcp
# INSTALL: No installation required
# GitHub: https://github.com/github/github-mcp-server
# BENEFIT: Official GitHub integration, no local setup
# GITHUB_MCP_URL=https://api.githubcopilot.com/mcp
GITHUB_MCP_URL=

# Optional: GitHub PAT (for private repos)
# GITHUB_TOKEN=

# =============================================================================
# NOTE: Agents automatically fallback to Bing Grounding + Foundry MCP
# if Phase 2 servers are unavailable. See .env_RECOMMENDED_UPDATES.md
# =============================================================================

# Azure Well-Architected Framework documentation base URL
AZURE_WAF_DOCS_URL=https://learn.microsoft.com/azure/well-architected/

# Azure Architecture Icons catalog URL
AZURE_ICONS_URL=https://learn.microsoft.com/azure/architecture/icons/

# Azure Architecture Icons CDN download URL
AZURE_ICONS_CDN_URL=https://arch-center.azureedge.net/icons/Azure_Public_Service_Icons.zip
# Override if Microsoft updates the URL or you need a specific version
# AZURE_ICONS_CDN_URL=